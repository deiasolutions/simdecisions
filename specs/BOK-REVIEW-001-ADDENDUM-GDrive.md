# BOK-REVIEW-001 Addendum: G-Drive Interface & Post-Reject QC

**Date:** 2026-02-04
**Author:** Q33N (Dave)
**Status:** DRAFT
**Extends:** BOK-REVIEW-001-GitHub-Tribunal-Pattern.md

---

## 1. Post-Reject Human Quality Control

### 1.1 Problem

If the tribunal rejects a submission, the human never sees it. This creates blind spots:

- Tribunal may be too strict (false negatives)
- Tribunal may misunderstand context
- Good work gets buried in `needs-work` limbo
- No feedback loop to calibrate tribunal

### 1.2 Solution

**Human QC sampling of rejected PRs:**

```
PR submitted â†’ Tribunal rejects â†’ Feedback posted
                                        â†“
                     [Sampling: 10-20% of rejects go to human QC queue]
                                        â†“
                     Human reviews: Was rejection correct?
                                        â†“
                     If tribunal wrong â†’ Override + calibration signal
                     If tribunal right â†’ Confirm + training signal
```

### 1.3 QC Queue

| Field | Description |
|-------|-------------|
| `qc_sampled` | Boolean â€” was this reject sampled for QC? |
| `qc_reviewed` | Boolean â€” has human reviewed? |
| `qc_verdict` | `tribunal_correct` / `tribunal_wrong` / `partial` |
| `qc_notes` | Human notes on what tribunal missed |

### 1.4 Calibration Signal

When human overrides tribunal:

```yaml
calibration_event:
  type: "tribunal_override"
  pr_number: 42
  tribunal_verdict: "reject"
  human_verdict: "approve"
  criteria_miscalibrated:
    - "narrow_scope"  # Tribunal was too strict here
  notes: "Config changes were justified, tribunal didn't read commit message"
```

Feed these back into judge prompt tuning.

---

## 2. Consensus Opinion (Narrative)

### 2.1 Current Model (Scores Only)

```
Gemini: 5/6
Codex: 3/6
Anthropic: 5/6
Total: 13/18 â†’ Pass
```

**Problem:** Scores don't capture WHY. No shared understanding.

### 2.2 New Model (Narrative + Vote)

Each judge writes:

1. **Assessment** â€” 2-3 paragraph analysis
2. **Vote** â€” Approve / Reject / Abstain
3. **Key concerns** â€” Bullet points
4. **Recommendation** â€” What should submitter do?

Then **Aggregator synthesizes consensus opinion:**

```markdown
## Tribunal Consensus Opinion

**Verdict:** APPROVE with notes (2-1 vote)

**Summary:**
The submission implements TASK-009 Event Ledger per ADR-001 specification.
All three judges agree the core implementation is sound. Test coverage is
comprehensive. One judge (Codex) flagged scope creep in config.py changes;
two judges accepted the justification in commit message.

**Key Agreement:**
- Schema matches spec exactly
- Tests comprehensive, coverage +4%
- Provenance clear (links to ADR-001, TASK-009)

**Key Disagreement:**
- Scope: Codex strict, Gemini/Anthropic accepted justification

**Recommendation to Human:**
Review the config.py changes. If acceptable, merge. If not, request
submitter split into separate PR.
```

---

## 3. Google Docs Integration

### 3.1 Why Google Docs?

| GitHub Reviews | Google Docs |
|----------------|-------------|
| Fragmented (per-file comments) | Single narrative document |
| Hard to compare judge opinions | Side-by-side judge sections |
| No real-time collaboration | Human can comment inline |
| Ephemeral (buried in PR history) | Persistent, searchable |
| Dev-focused format | Human-readable format |

### 3.2 Document Structure

```
ğŸ“„ [TASK-009] Event Ledger v1 â€” Tribunal Review

â”œâ”€â”€ Header
â”‚   â”œâ”€â”€ PR Link
â”‚   â”œâ”€â”€ Task Reference
â”‚   â”œâ”€â”€ Submitting Agent
â”‚   â””â”€â”€ Tribunal Date
â”‚
â”œâ”€â”€ Judge 1: Gemini Q33N
â”‚   â”œâ”€â”€ Assessment (narrative)
â”‚   â”œâ”€â”€ Scores (I/N/V/E/S/T)
â”‚   â”œâ”€â”€ Vote: APPROVE
â”‚   â””â”€â”€ Notes
â”‚
â”œâ”€â”€ Judge 2: Codex Q33N
â”‚   â”œâ”€â”€ Assessment (narrative)
â”‚   â”œâ”€â”€ Scores (I/N/V/E/S/T)
â”‚   â”œâ”€â”€ Vote: REQUEST CHANGES
â”‚   â””â”€â”€ Notes
â”‚
â”œâ”€â”€ Judge 3: Anthropic Q33N
â”‚   â”œâ”€â”€ Assessment (narrative)
â”‚   â”œâ”€â”€ Scores (I/N/V/E/S/T)
â”‚   â”œâ”€â”€ Vote: APPROVE
â”‚   â””â”€â”€ Notes
â”‚
â”œâ”€â”€ Consensus Opinion
â”‚   â”œâ”€â”€ Aggregated verdict
â”‚   â”œâ”€â”€ Key agreements
â”‚   â”œâ”€â”€ Key disagreements
â”‚   â””â”€â”€ Recommendation
â”‚
â”œâ”€â”€ Human Decision
â”‚   â”œâ”€â”€ Verdict: [pending]
â”‚   â”œâ”€â”€ Notes: [pending]
â”‚   â””â”€â”€ Timestamp: [pending]
â”‚
â””â”€â”€ Metadata
    â”œâ”€â”€ Embeddings scores
    â”œâ”€â”€ Moderation results
    â””â”€â”€ Kaizen metrics
```

### 3.3 G-Drive Folder Structure

```
SimDecisions Tribunal/
â”œâ”€â”€ 2026/
â”‚   â”œâ”€â”€ 02/
â”‚   â”‚   â”œâ”€â”€ 04/
â”‚   â”‚   â”‚   â”œâ”€â”€ [TASK-009] Event Ledger v1 â€” Tribunal Review.gdoc
â”‚   â”‚   â”‚   â”œâ”€â”€ [TASK-010] API Routes â€” Tribunal Review.gdoc
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Templates/
â”‚   â””â”€â”€ Tribunal Review Template.gdoc
â”œâ”€â”€ QC Queue/
â”‚   â””â”€â”€ [Sampled rejects for human review]
â””â”€â”€ Calibration Log/
    â””â”€â”€ Tribunal Override Events.gsheet
```

---

## 4. G-Drive Interface (PyBee)

### 4.1 Interface Spec

```python
# PYBEE: gdrive-tribunal-writer

class GDriveTribunalWriter:
    """
    Writes tribunal reviews to Google Docs.
    Reads human decisions from docs.
    """

    def create_review_doc(
        self,
        task_id: str,
        pr_number: int,
        pr_title: str,
        submitter: str
    ) -> str:
        """
        Create new tribunal review doc from template.
        Returns: doc_id
        """
        pass

    def write_judge_section(
        self,
        doc_id: str,
        judge_id: str,
        assessment: str,
        scores: Dict[str, int],
        vote: str,
        notes: str
    ) -> None:
        """
        Write one judge's section to the doc.
        """
        pass

    def write_consensus(
        self,
        doc_id: str,
        verdict: str,
        summary: str,
        agreements: List[str],
        disagreements: List[str],
        recommendation: str
    ) -> None:
        """
        Write aggregated consensus section.
        """
        pass

    def read_human_decision(
        self,
        doc_id: str
    ) -> Optional[Dict]:
        """
        Poll doc for human decision.
        Returns None if not yet decided.
        Returns {verdict, notes, timestamp} if decided.
        """
        pass

    def move_to_archive(
        self,
        doc_id: str,
        outcome: str  # "merged" | "abandoned" | "qc_override"
    ) -> None:
        """
        Move completed review to archive folder.
        """
        pass
```

### 4.2 Authentication

- Service account with G-Drive API access
- Scoped to SimDecisions Tribunal folder only
- Credentials in secrets manager (not in repo)

### 4.3 Workflow Integration

```
1. PR opened
2. Aggregator creates Google Doc (from template)
3. Each judge writes their section to doc (parallel)
4. Aggregator writes consensus section
5. Aggregator posts doc link to GitHub PR comment
6. Human reviews doc, fills in decision section
7. Aggregator polls for decision
8. On decision: update GitHub labels, write to ledger, archive doc
```

---

## 5. Updated Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent       â”‚
â”‚ submits PR  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TRIBUNAL                              â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Gemini  â”‚    â”‚ Codex   â”‚    â”‚Anthropicâ”‚              â”‚
â”‚  â”‚ writes  â”‚    â”‚ writes  â”‚    â”‚ writes  â”‚              â”‚
â”‚  â”‚ to doc  â”‚    â”‚ to doc  â”‚    â”‚ to doc  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                      â–¼                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚              â”‚ Aggregator   â”‚                            â”‚
â”‚              â”‚ writes       â”‚                            â”‚
â”‚              â”‚ consensus    â”‚                            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Google Doc   â”‚
              â”‚ with full    â”‚
              â”‚ review       â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PASS         â”‚           â”‚ REJECT       â”‚
â”‚ â†’ ready-for- â”‚           â”‚ â†’ needs-work â”‚
â”‚    dave      â”‚           â”‚ â†’ feedback   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚
       â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dave reviews â”‚           â”‚ QC Sample?   â”‚
â”‚ doc, decides â”‚           â”‚ 10-20%       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                          â”‚
       â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Merge / More â”‚           â”‚ Human QC     â”‚
â”‚ changes      â”‚           â”‚ reviews      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ rejection    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ Calibration  â”‚
                           â”‚ signal       â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Implementation Tasks

| Task | Description | Effort |
|------|-------------|--------|
| TASK-030 | Create G-Drive interface PyBee | 4 hrs |
| TASK-031 | Design tribunal review doc template | 2 hrs |
| TASK-032 | Update aggregator to write consensus narrative | 3 hrs |
| TASK-033 | Implement QC sampling for rejects | 2 hrs |
| TASK-034 | Add calibration signal to judge prompt tuning | 3 hrs |
| TASK-035 | Create QC Queue folder and workflow | 2 hrs |

---

## 7. Open Questions

1. **Polling frequency:** How often does aggregator check for human decision?
2. **Template format:** What exact sections in the Google Doc template?
3. **QC sample rate:** 10%? 20%? Configurable per project?
4. **Multi-reviewer:** Can multiple humans comment on same doc?

---

*Addendum to BOK-REVIEW-001. G-Drive becomes the human-readable record of tribunal decisions.*
